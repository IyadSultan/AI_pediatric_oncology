{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJazahK1khYFN8/LufPaRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IyadSultan/AI_pediatric_oncology/blob/main/09_Feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering for Tabular & Time-Series Data  \n",
        "**Level:** Beginner → Intermediate  **Duration:** ≈ 2 hours  \n",
        "\n",
        "Feature engineering transforms raw data into informative features that boost model performance.  \n",
        "This notebook covers both **tabular** and **time-series** techniques:\n",
        "\n",
        "* Handling missing values  \n",
        "* Encoding categorical variables  \n",
        "* Binning & discretization  \n",
        "* Feature scaling & transformation  \n",
        "* Feature extraction (datetime parts, polynomial terms)  \n",
        "* Interaction features  \n",
        "* Feature-selection methods  \n",
        "* Time-series specifics (lags, rollings, seasonal features)  \n",
        "* Automated FE with **tsfresh** & **Featuretools**\n",
        "\n",
        "> **How to use this notebook**  \n",
        "> 1. Run the cells in order.  \n",
        "> 2. Tweak code or plug in your own data.  \n",
        "> 3. Install extra libraries when prompted.\n"
      ],
      "metadata": {
        "id": "-ROxNvadHhui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup & Sample Data -----------------------------------\n",
        "!pip install seaborn tsfresh featuretools --quiet"
      ],
      "metadata": {
        "id": "nBqPmSQ8HiPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, seaborn as sns\n",
        "df = sns.load_dataset(\"titanic\")\n",
        "print(\"Titanic shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1FxZkcCHS2pC",
        "outputId": "4da0fc47-8ea5-4e24-f3b6-52a0b8c9e08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic shape: (891, 15)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
              "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
              "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
              "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
              "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
              "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
              "\n",
              "     who  adult_male deck  embark_town alive  alone  \n",
              "0    man        True  NaN  Southampton    no  False  \n",
              "1  woman       False    C    Cherbourg   yes  False  \n",
              "2  woman       False  NaN  Southampton   yes   True  \n",
              "3  woman       False    C  Southampton   yes  False  \n",
              "4    man        True  NaN  Southampton    no   True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9589813-9f3b-4014-a280-d53070023b38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9589813-9f3b-4014-a280-d53070023b38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9589813-9f3b-4014-a280-d53070023b38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9589813-9f3b-4014-a280-d53070023b38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-90def0f6-93d2-421e-9bf9-1a495df7a844\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90def0f6-93d2-421e-9bf9-1a495df7a844')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-90def0f6-93d2-421e-9bf9-1a495df7a844 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sibsp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Third\",\n          \"First\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"who\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"man\",\n          \"woman\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adult_male\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"deck\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"C\",\n          \"E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embark_town\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Southampton\",\n          \"Cherbourg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alone\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1  Handling Missing Values  \n",
        "\n",
        "From the output above, we can observe the count of missing values per column. In the Titanic dataset, the age and embarked columns have a few missing values, and the deck column has a lot of missing values. (The deck feature indicates passenger deck levels on the ship, and many entries are missing since not all passengers have a recorded deck.)\n",
        "**Common strategies**\n",
        "\n",
        "| Strategy | When to use | Caveats |\n",
        "|----------|-------------|---------|\n",
        "| **Drop rows/cols** | few NaNs or column nearly empty | data loss |\n",
        "| **Impute constant** | categorical “Unknown”, numeric 0 | may hide signal |\n",
        "| **Statistical impute** | mean/median/mode | assumes missing at random |\n",
        "| **Model-based impute** | KNN / Iterative | heavier, possible bias |\n",
        "| **Missing flag** | when “missingness” is informative | add extra column |\n",
        "\n",
        "\n",
        "**Strategy 1:** Removing missing data\n",
        "If a column is mostly missing (for example, deck is missing for the majority of passengers), it might be prudent to drop that column entirely, as it may not be very useful. Similarly, if only a few rows have missing data but in critical columns, and if dropping them doesn't lose too much data, we might drop those rows. Let's drop the deck column and see how many rows remain if we drop any rows with any missing values:\n",
        "\n"
      ],
      "metadata": {
        "id": "MvwiWN-_HiXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Missing-value inspection ------------------------------\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "hVbWPS15Hieu",
        "outputId": "9ba1e1ea-7e89-4d96-8227-4ef398ae68a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived         0\n",
              "pclass           0\n",
              "sex              0\n",
              "age            177\n",
              "sibsp            0\n",
              "parch            0\n",
              "fare             0\n",
              "embarked         2\n",
              "class            0\n",
              "who              0\n",
              "adult_male       0\n",
              "deck           688\n",
              "embark_town      2\n",
              "alive            0\n",
              "alone            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>survived</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pclass</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sibsp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parch</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fare</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embarked</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>who</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>adult_male</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deck</th>\n",
              "      <td>688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embark_town</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alive</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alone</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Drop 'deck' and view size impact ----------------------\n",
        "df = df.drop(columns=[\"deck\"])\n",
        "print(\"Cols after drop:\", df.columns.tolist())\n",
        "print(\"Rows after dropping any-NaN rows:\",\n",
        "      len(df.dropna()), \"of\", len(df))\n"
      ],
      "metadata": {
        "id": "Ut5d2lztHwSx",
        "outputId": "ac1e3002-6fdb-4236-c5ef-35e2581fee04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cols after drop: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive', 'alone']\n",
            "Rows after dropping any-NaN rows: 712 of 891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the output, notice how many rows would be left after dropping all rows with any missing value. We do this check to illustrate the impact: if a lot of rows are dropped, we might prefer imputation instead. In this case, dropping all missing data might remove a significant number of passengers, which could throw away useful information. Since we want to keep as much data as possible, let's opt for imputation for the remaining missing values (Age and Embarked):\n",
        "**Strategy 2:** Imputing missing values\n",
        "- For the numeric age feature, a common choice is to fill missing ages with the median age (median is used instead of mean if the distribution is skewed or has outliers).\n",
        "- For the categorical embarked feature, we can fill missing entries with the mode (the most common port of embarkation).\n",
        "We'll perform these imputations using pandas. (Alternatively, one can use scikit-learn's SimpleImputer – we'll show that as well.)"
      ],
      "metadata": {
        "id": "Eww-hOVqTcHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing Age with median, and missing Embarked with mode\n",
        "median_age = df['age'].median()\n",
        "mode_embarked = df['embarked'].mode()[0]  # mode() returns a Series\n",
        "print(\"Imputing missing ages with median:\", median_age)\n",
        "print(\"Imputing missing embarked with mode:\", mode_embarked)\n",
        "\n",
        "df['age'] = df['age'].fillna(median_age)\n",
        "df['embarked'] = df['embarked'].fillna(mode_embarked)\n",
        "\n",
        "# Verify no missing values remain in age and embarked\n",
        "print(\"Remaining missing values:\", df[['age','embarked']].isnull().sum().to_dict())\n"
      ],
      "metadata": {
        "id": "t20Ja8uxHxmf",
        "outputId": "3b339fa7-2483-41ff-ea19-e46665780507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing missing ages with median: 28.0\n",
            "Imputing missing embarked with mode: S\n",
            "Remaining missing values: {'age': 0, 'embarked': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After imputation, the age and embarked columns should have no missing values. We filled age with the median (~28 years old, for example) and embarked with the most common port (likely \"S\" for Southampton in this dataset).\n",
        "\n",
        "**Using scikit-learn's Imputer:**\n",
        "For completeness, let's also demonstrate using scikit-learn's SimpleImputer to fill missing values. This is useful when building machine learning pipelines, so that imputation is combined with modeling steps and can be applied consistently to training and test data."
      ],
      "metadata": {
        "id": "essn8FvqUI8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pipeline-friendly imputation demo ---------------------\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "sample = sns.load_dataset(\"titanic\").drop(columns=[\"deck\"])\n",
        "imp_med  = SimpleImputer(strategy=\"median\")\n",
        "imp_freq = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "sample[\"age\"]      = imp_med .fit_transform(sample[[\"age\"]])\n",
        "sample[\"embarked\"] = imp_freq.fit_transform(sample[[\"embarked\"]])\n",
        "sample[[\"age\",\"embarked\"]].isna().sum()\n"
      ],
      "metadata": {
        "id": "ElGz5i3EH1oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2  Encoding Categorical Variables  \n",
        "\n",
        "* **One-Hot** for nominal (sex, embarked)  \n",
        "* **Ordinal** for ordered (First > Second > Third)  \n",
        "* Avoid plain label-encoding on nominal features.\n",
        "\n",
        "We’ll one-hot `sex` & `embarked`, then ordinal-encode `class`.\n"
      ],
      "metadata": {
        "id": "rIwKdEjtHimK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- One-Hot encode ----------------------------------------\n",
        "dummies = pd.get_dummies(df[[\"sex\",\"embarked\"]], drop_first=False)\n",
        "df      = pd.concat([df, dummies], axis=1).drop(columns=[\"sex\",\"embarked\"])\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "id": "g-RME0NrHitX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ordinal encode 'class' --------------------------------\n",
        "class_map = {\"Third\":1,\"Second\":2,\"First\":3}\n",
        "df[\"class_encoded\"] = df[\"class\"].map(class_map)\n",
        "df[[\"class\",\"class_encoded\"]].head()\n"
      ],
      "metadata": {
        "id": "16mY1BNwH6yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3  Binning & Discretization  \n",
        "\n",
        "Why bin? Robust to outliers, capture step-wise effects, simplify models.\n",
        "\n",
        "* **Domain bins** – age groups  \n",
        "* **Quantile bins** – fare quartiles  \n",
        "* **KBinsDiscretizer** – automated (uniform / quantile)\n",
        "\n",
        "We’ll create `AgeGroup` (Child/Teen/Adult/Senior) and fare quartiles.\n"
      ],
      "metadata": {
        "id": "NNyt4bBtHiz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Age domain bins ---------------------------------------\n",
        "bins   = [0,12,19,59,np.inf]\n",
        "labels = [\"Child\",\"Teenager\",\"Adult\",\"Senior\"]\n",
        "df[\"AgeGroup\"] = pd.cut(df[\"age\"], bins=bins, labels=labels)\n",
        "df[[\"age\",\"AgeGroup\"]].head()\n"
      ],
      "metadata": {
        "id": "WeKvLyXAHi7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fare quartile bins ------------------------------------\n",
        "df[\"Fare_bin\"] = pd.qcut(df[\"fare\"], q=4, labels=[\"Q1\",\"Q2\",\"Q3\",\"Q4\"])\n",
        "df[\"Fare_bin\"].value_counts()\n"
      ],
      "metadata": {
        "id": "oN1dvkE0IAWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KBinsDiscretizer demo ---------------------------------\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "kb = KBinsDiscretizer(n_bins=3, encode=\"ordinal\", strategy=\"uniform\")\n",
        "df[\"age_bin3\"] = kb.fit_transform(df[[\"age\"]])\n",
        "df[[\"age\",\"age_bin3\"]].head()\n"
      ],
      "metadata": {
        "id": "ckL55YqlICrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4  Feature Scaling & Transformation  \n",
        "\n",
        "Models like k-NN, SVM, neural nets need comparable scales.\n",
        "\n",
        "* **StandardScaler** – mean 0, std 1  \n",
        "* **MinMaxScaler** – 0 → 1  \n",
        "* **Log / Box-Cox** – fix skew\n",
        "\n",
        "We’ll scale `age`, `fare`, `sibsp`, `parch`, and add a log-fare.\n"
      ],
      "metadata": {
        "id": "NMhwhvRYHjBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "num_cols = [\"age\",\"fare\",\"sibsp\",\"parch\"]\n",
        "orig     = df[num_cols].copy()\n",
        "\n",
        "std = StandardScaler().fit_transform(orig)\n",
        "mm  = MinMaxScaler().fit_transform(orig)\n",
        "\n",
        "print(\"Std-scaled sample:\\n\", pd.DataFrame(std, columns=num_cols).head())\n",
        "\n",
        "df[\"fare_log10\"] = np.log10(df[\"fare\"] + 1e-5)\n",
        "df[[\"fare\",\"fare_log10\"]].head()\n"
      ],
      "metadata": {
        "id": "A5BCrwEhHjIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5  Feature Extraction  \n",
        "\n",
        "### 5.1 Datetime Parts  \n",
        "Break timestamps into year, month, dow, hour, etc.\n",
        "\n",
        "### 5.2 Polynomial Features  \n",
        "`PolynomialFeatures(degree=2)` adds squares & interactions.\n"
      ],
      "metadata": {
        "id": "RmFYi4p8HjPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Datetime parts demo -----------------------------------\n",
        "dates = pd.DataFrame({\"purchase_date\": pd.to_datetime([\n",
        "    \"2021-01-01 14:23\", \"2021-07-15 09:00\",\n",
        "    \"2022-03-05 20:45\", \"2022-03-06 12:00\",\n",
        "    \"2022-12-25 00:00\"])})\n",
        "\n",
        "dates[\"year\"]  = dates[\"purchase_date\"].dt.year\n",
        "dates[\"month\"] = dates[\"purchase_date\"].dt.month\n",
        "dates[\"dow\"]   = dates[\"purchase_date\"].dt.day_name()\n",
        "dates[\"hour\"]  = dates[\"purchase_date\"].dt.hour\n",
        "dates\n"
      ],
      "metadata": {
        "id": "BCE9Zh-tHjWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PolynomialFeatures demo -------------------------------\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "af_poly = poly.fit_transform(df[[\"age\",\"fare\"]].fillna(0))\n",
        "pd.DataFrame(af_poly, columns=poly.get_feature_names_out([\"age\",\"fare\"])).head()\n"
      ],
      "metadata": {
        "id": "26yVLkDkIKbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6  Interaction Features  \n",
        "\n",
        "Domain-driven combos often matter:\n",
        "\n",
        "* `family_size = sibsp + parch + 1`  \n",
        "* `is_alone` flag  \n",
        "* `fare_per_person` ratio  \n",
        "* Categorical combos like `sex_pclass`\n"
      ],
      "metadata": {
        "id": "sJRWQQzWHjc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Family size & friends ---------------------------------\n",
        "df[\"family_size\"] = df[\"sibsp\"] + df[\"parch\"] + 1\n",
        "df[\"is_alone\"]    = (df[\"family_size\"] == 1).astype(int)\n",
        "df[\"fare_per_person\"] = df[\"fare\"] / df[\"family_size\"]\n",
        "df[[\"sibsp\",\"parch\",\"family_size\",\"is_alone\",\"fare_per_person\"]].head()\n"
      ],
      "metadata": {
        "id": "xNqkXoQuHjj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- sex_pclass combo (fresh dataset for demo) -------------\n",
        "raw = sns.load_dataset(\"titanic\")\n",
        "raw[\"sex_pclass\"] = raw[\"sex\"] + \"_\" + raw[\"pclass\"].astype(str)\n",
        "raw[\"sex_pclass\"].value_counts().head()\n"
      ],
      "metadata": {
        "id": "TyhVlKcQIQAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7  Feature Selection  \n",
        "\n",
        "* **Filter** – SelectKBest(ANOVA)  \n",
        "* **Embedded** – tree importances  \n",
        "* **Wrapper** – RFE\n",
        "\n",
        "We’ll build a synthetic dataset and try each.\n"
      ],
      "metadata": {
        "id": "xq4wiWWsHjra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.ensemble  import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20,\n",
        "                           n_informative=5, n_redundant=5,\n",
        "                           random_state=42, shuffle=False)\n",
        "\n",
        "# Filter\n",
        "flt = SelectKBest(f_classif, k=5).fit(X, y)\n",
        "print(\"Filter selected:\", flt.get_support(indices=True))\n",
        "\n",
        "# Embedded\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42).fit(X, y)\n",
        "print(\"Top RF features:\", np.argsort(rf.feature_importances_)[::-1][:5])\n",
        "\n",
        "# Wrapper\n",
        "rfe = RFE(LogisticRegression(max_iter=1000, solver=\"liblinear\"), n_features_to_select=5)\n",
        "rfe.fit(X, y)\n",
        "print(\"RFE selected:\", np.where(rfe.support_)[0])\n"
      ],
      "metadata": {
        "id": "E1FXOK2UHjwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8  Time-Series Feature Engineering  \n",
        "\n",
        "Key ideas: **lags, rolling stats, diffs, seasonal parts**.\n"
      ],
      "metadata": {
        "id": "MUqPPQ34Hj2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simulate monthly series -------------------------------\n",
        "idx   = pd.date_range(\"2019-01\", periods=36, freq=\"M\")\n",
        "t     = np.arange(36)\n",
        "np.random.seed(0)\n",
        "vals  = 10 + 0.5*t + 5*np.sin(2*np.pi*t/12) + np.random.normal(0,2,36)\n",
        "ts    = pd.DataFrame({\"Value\": vals}, index=idx)\n",
        "\n",
        "# Lag & rolling\n",
        "ts[\"lag1\"]   = ts[\"Value\"].shift(1)\n",
        "ts[\"lag12\"]  = ts[\"Value\"].shift(12)\n",
        "ts[\"roll3\"]  = ts[\"Value\"].rolling(3).mean()\n",
        "ts[\"diff1\"]  = ts[\"Value\"].diff()\n",
        "ts.tail()\n"
      ],
      "metadata": {
        "id": "OCXhuqpVHj9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9  Automated Feature Engineering  \n",
        "\n",
        "### 9.1 tsfresh – exhaustive stats for each time-series  \n",
        "### 9.2 Featuretools – Deep Feature Synthesis for relational data\n"
      ],
      "metadata": {
        "id": "vSi2qAAPHkDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- tsfresh minimal example -------------------------------\n",
        "from tsfresh.feature_extraction import extract_features\n",
        "mini = ts.reset_index().rename(columns={\"index\":\"time\"})\n",
        "mini[\"id\"] = 1\n",
        "features = extract_features(mini, column_id=\"id\", column_sort=\"time\",\n",
        "                            default_fc_parameters={\"mean\":None,\"median\":None})\n",
        "features\n"
      ],
      "metadata": {
        "id": "wMTxypxgHkJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Featuretools mock-customer demo -----------------------\n",
        "import featuretools as ft\n",
        "data = ft.demo.load_mock_customer()\n",
        "es = ft.EntitySet(id=\"cust\")\n",
        "es = es.add_dataframe(\"customers\",   data[\"customers\"],   index=\"customer_id\")\n",
        "es = es.add_dataframe(\"sessions\",    data[\"sessions\"],    index=\"session_id\",    time_index=\"session_start\")\n",
        "es = es.add_dataframe(\"transactions\",data[\"transactions\"],index=\"transaction_id\",time_index=\"transaction_time\")\n",
        "es = es.add_relationship(parent_dataframe_name=\"customers\",  parent_column_name=\"customer_id\",\n",
        "                         child_dataframe_name=\"sessions\",    child_column_name=\"customer_id\")\n",
        "es = es.add_relationship(parent_dataframe_name=\"sessions\",   parent_column_name=\"session_id\",\n",
        "                         child_dataframe_name=\"transactions\",child_column_name=\"session_id\")\n",
        "fm, defs = ft.dfs(entityset=es, target_dataframe_name=\"customers\", max_depth=2)\n",
        "fm.head()\n"
      ],
      "metadata": {
        "id": "fKDxNh5rIaMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aT_AoBnCHmbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA1ia8bLHgdw"
      },
      "outputs": [],
      "source": []
    }
  ]
}